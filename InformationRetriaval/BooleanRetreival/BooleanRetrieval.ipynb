{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Boolean Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import total_ordering, reduce\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMMENTS ON CODE: \n",
    "Given a class defining one or more \n",
    "rich comparison ordering methods, \n",
    "this class decorator @total_ordering supplies the rest. \n",
    "This simplifies the effort involved in specifying all\n",
    "of the possible rich comparison operations:\n",
    "\n",
    "The class must define one of __lt__(), __le__(),\n",
    "__gt__(), or __ge__(). \n",
    "In addition, the class should supply an __eq__() \n",
    "method.\n",
    "\"\"\"\n",
    "\n",
    "@total_ordering\n",
    "class Posting:\n",
    "    \n",
    "    def __init__(self, docID):\n",
    "        self._docID = docID\n",
    "        \n",
    "    def get_from_corpus(self, corpus):\n",
    "        return corpus[self._docID]\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self._docID == other._docID\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self._docID > other._docID\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self._docID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posting Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostingList:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._postings = []\n",
    "        \n",
    "    @classmethod\n",
    "    def from_docID(cls, docID):\n",
    "        plist = cls()\n",
    "        plist._postings = [(Posting(docID))]\n",
    "        return plist\n",
    "    \n",
    "    @classmethod\n",
    "    def from_posting_list(cls, postingList):\n",
    "        plist = cls()\n",
    "        plist._postings = postingList\n",
    "        return plist\n",
    "    \n",
    "    def merge(self, other):\n",
    "        i = 0\n",
    "        last = self._postings[-1]\n",
    "        while (i < len(other._postings) and last == other._postings[i]):\n",
    "            i += 1\n",
    "        self._postings += other._postings[i:]\n",
    "        \n",
    "    def intersection(self, other):\n",
    "        intersection = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while (i < len(self._postings) and j < len(other._postings)):\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                intersection.append(self._postings[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        return PostingList.from_posting_list(intersection)\n",
    "    \n",
    "    def union(self, other):\n",
    "        union = []\n",
    "        i = 0\n",
    "        j = 0 \n",
    "        while (i < len(self._postings) and j < len(other._postings)):\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                union.append(self._postings[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                union.append(self._postings[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                union.append(other._postings[j])\n",
    "                j += 1\n",
    "        for k in range(1, len(self._postings)):\n",
    "            union.append(self.postings[k])\n",
    "        for k in range(1, len(self._postings)):\n",
    "            union.append(other.postings[k])\n",
    "        return PostingList.from_posting_list(union)\n",
    "    \n",
    "    def get_from_corpus(self, corpus):\n",
    "        return list(map(lambda x: x.get_from_corpus(corpus), self._postings))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ', '.join(map(str, self._postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpossibleMergeError(Exception):\n",
    "    pass\n",
    "\n",
    "@total_ordering\n",
    "class Term:\n",
    "    \n",
    "    def __init__(self, term, docID):\n",
    "        self.term = term\n",
    "        self.posting_list = PostingList.from_docID(docID)\n",
    "        \n",
    "    def merge(self, other):\n",
    "        if (self.term == other.term):\n",
    "            self.posting_list.merge(other.posting_list)\n",
    "        else:\n",
    "            raise ImpossibleMergeError\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.term == other.term\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.term > other.term\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.term + \": \" + repr(self.posting_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    no_punctuation = re.sub(r'[^\\w^\\s^-]','',text)\n",
    "    downcase = no_punctuation.lower()\n",
    "    return downcase\n",
    "\n",
    "def tokenize(movie):\n",
    "    text = normalize(movie.description)\n",
    "    return list(text.split())\n",
    "\n",
    "class InvertedIndex:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._dictionary = []\n",
    "        \n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        intermediate_dict = {}\n",
    "        for docID, document in enumerate(corpus):\n",
    "            tokens = tokenize(document)\n",
    "            for token in tokens:\n",
    "                term = Term(token, docID)\n",
    "                try:\n",
    "                    intermediate_dict[token].merge(term)\n",
    "                except KeyError:\n",
    "                    intermediate_dict[token] = term\n",
    "            if (docID % 1000 == 0):\n",
    "                print(\"ID: \" + str(docID))\n",
    "        idx = cls()\n",
    "        idx._dictionary = sorted(intermediate_dict.values())\n",
    "        return idx\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        for term in self._dictionary:\n",
    "            if term.term == key:\n",
    "                return term.posting_list\n",
    "        raise KeyError\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"A dictionary with \" + str(len(self._dictionary)) + \" terms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDescription:\n",
    "    \n",
    "    def __init__(self, title, description):\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.title\n",
    "    \n",
    "\n",
    "def read_movie_description():\n",
    "    filename = 'MovieSummaries/plot_summaries.txt'\n",
    "    movie_names_file = 'MovieSummaries/movie.metadata.tsv'\n",
    "    \n",
    "    with open(movie_names_file, 'r') as csv_file:\n",
    "        movie_names = csv.reader(csv_file, delimiter='\\t')\n",
    "        names_table = {}\n",
    "        for name in movie_names:\n",
    "            names_table[name[0]] = name[2]\n",
    "    \n",
    "    with open(filename, 'r') as csv_file:\n",
    "        descriptions = csv.reader(csv_file, delimiter='\\t')\n",
    "        corpus = [] \n",
    "        for desc in descriptions:\n",
    "            try:\n",
    "                movie = MovieDescription(names_table[desc[0]], desc[1])\n",
    "                corpus.append(movie)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRsystem:\n",
    "    \n",
    "    def __init__(self, corpus, index):\n",
    "        self._corpus = corpus\n",
    "        self._index = index\n",
    "        \n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        index = InvertedIndex.from_corpus(corpus)\n",
    "        return cls(corpus, index)\n",
    "    \n",
    "    def answer_query(self, words): #['cats', 'batman']\n",
    "        norm_words = map(normalize, words)\n",
    "        postings = map(lambda w: self._index[w], norm_words)\n",
    "        plist = reduce(lambda x, y: x.intersection(y), postings)\n",
    "        return plist.get_from_corpus(self._corpus)\n",
    "    \n",
    "    \n",
    "def query(ir, text):\n",
    "    words = text.split()\n",
    "    answer = ir.answer_query(words)\n",
    "    for movie in answer:\n",
    "        print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_movie_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 0\n",
      "ID: 1000\n",
      "ID: 2000\n",
      "ID: 3000\n",
      "ID: 4000\n",
      "ID: 5000\n",
      "ID: 6000\n",
      "ID: 7000\n",
      "ID: 8000\n",
      "ID: 9000\n",
      "ID: 10000\n",
      "ID: 11000\n",
      "ID: 12000\n",
      "ID: 13000\n",
      "ID: 14000\n",
      "ID: 15000\n",
      "ID: 16000\n",
      "ID: 17000\n",
      "ID: 18000\n",
      "ID: 19000\n",
      "ID: 20000\n",
      "ID: 21000\n",
      "ID: 22000\n",
      "ID: 23000\n",
      "ID: 24000\n",
      "ID: 25000\n",
      "ID: 26000\n",
      "ID: 27000\n",
      "ID: 28000\n",
      "ID: 29000\n",
      "ID: 30000\n",
      "ID: 31000\n",
      "ID: 32000\n",
      "ID: 33000\n",
      "ID: 34000\n",
      "ID: 35000\n",
      "ID: 36000\n",
      "ID: 37000\n",
      "ID: 38000\n",
      "ID: 39000\n",
      "ID: 40000\n",
      "ID: 41000\n",
      "ID: 42000\n"
     ]
    }
   ],
   "source": [
    "idx = InvertedIndex.from_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334, 2990, 3463, 3519, 3545, 5510, 6854, 7105, 7358, 8467, 9503, 10360, 10727, 10933, 12458, 12492, 12967, 13095, 14199, 17366, 18875, 19381, 19675, 20598, 20808, 21070, 22147, 24393, 24484, 24658, 25866, 30601, 31272, 31508, 33213, 33638, 35356, 35980, 37238, 37389, 38152, 39092, 40499, 40596, 40821"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = IRsystem(corpus, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lord of the Rings: The Fellowship of the Ring\n",
      "The Lord of the Rings\n",
      "The Hunt for Gollum\n",
      "The Return of the King\n",
      "Date Movie\n",
      "The Lord of the Rings: The Two Towers\n",
      "The Lord of the Rings: The Return of the King\n"
     ]
    }
   ],
   "source": [
    "query(ir, \"frodo Gandalf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars Episode V: The Empire Strikes Back\n",
      "Something, Something, Something Dark Side\n",
      "Return of the Ewok\n",
      "Star Wars Episode III: Revenge of the Sith\n",
      "Star Wars Episode VI: Return of the Jedi\n",
      "It's a Trap!\n"
     ]
    }
   ],
   "source": [
    "query(ir, \"luke yoda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
